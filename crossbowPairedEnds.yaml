name: Crossbow, pair-ended reads
description: A scalable software pipeline for whole genome resequencing analysis. It combines Bowtie, an ultrafast and memory efficient short read aligner, and SoapSNP, and an accurate genotyper. These tools are combined in an automatic, parallel pipeline.
category: Genetics
version: 1.1.2
website: http://bowtie-bio.sourceforge.net/crossbow
author: Ben Langmead et al.

cluster:
  image: us-east-1/ami-31bc7758
  type: m1.large,m1.xlarge
  ports: 80,50030,50070
  user: ubuntu
  service: hadoop
  installMapred: true
  initScript: install.sh

mapred:

##              -inputformat org.apache.hadoop.mapred.lib.NLineInputFormat

  steps:

#    - name: Preprocess
#      mapper: Copy.pl --compress=bzip2 --stop=0 --maxperfile=1000000 --s --push=$temp/preproc
#      params: -input $manifest
#              -output $temp/preproc
#              -numReduceTasks 0
#              -inputformat org.apache.hadoop.mapred.lib.NLineInputFormat
#              -file Copy.pl
#              -file Get.pm
#              -file Counters.pm
#              -file Util.pm
#              -file Tools.pm
#              -file AWS.pm

    - name: Format forward reads
      mapper: /home/alexey/mr_python/mapperForward.py $header_separator
      params: -D mapred.reduce.tasks=0
              -Dmapred.output.compress=true
              -Dmapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec
              -input $forwardReads
              -output $temp/formatForward
              -file /home/alexey/mr_python/mapperForward.py


    - name: Format reverse reads
      mapper: /home/alexey/mr_python/mapperReverse.py $header_separator
      params: -Dmapred.reduce.tasks=0
              -Dmapred.output.compress=true
              -Dmapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec
              -input $reverseReads
              -output $temp/formatReverse
              -file /home/alexey/mr_python/mapperReverse.py 


#
    - name: Merge forward and reverse reads
      mapper: /bin/cat
      reducer: /home/alexey/mr_python/reducerMerge.py
      params: -Dmapred.compress.map.output=true
              -Dmapred.map.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec
              -Dmapred.reduce.tasks=112
              -Dmapred.output.compress=true
              -Dmapred.output.compression.codec=org.apache.hadoop.io.compress.BZip2Codec
              -Dmap.output.key.field.separator=.
              -Dmapred.text.key.partitioner.options=-k1,1
              -Dmapred.reduce.slowstart.completed.maps=1.0
              -Dio.sort.record.percent=0.06
              -Dio.sort.mb=700
              -Dtasktracker.http.threads=80
              -Dio.sort.factor=5
              -Dmapred.child.java.opts=-Xmx1000m
              -Dmapred.inmem.merge.threshold=0
              -Dmapred.reduce.parallel.copies=50
              -input $temp/format*              
              -output $temp/formatMerge
              -file /home/alexey/mr_python/reducerMerge.py
              -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner
                                                                                                                                                   
                                                                                                                                                   
    - name: Alignment                                                                                                                              
      mapper: Align.pl  --discard-reads=0 --ref=$reference --destdir=/tmp/$job_id --partlen=1000000 --qual=$quality --truncate=0 -- --partition 1000000 --mm -t --hadoopout --startverbose $bowtie_arguments
      params: -Dmapred.output.compress=true
              -Dmapred.output.compression.codec=org.apache.hadoop.io.compress.BZip2Codec
              -input $temp/formatMerge
              -output $temp/align                                                                                                                  
              -numReduceTasks 0 
              -file Align.pl
              -file Get.pm
              -file Counters.pm
              -file Util.pm
              -file Tools.pm
              -file AWS.pm
#


    - name: Call SNPs
      mapper: /bin/cat
      reducer: Soapsnp.pl --discard-ref-bins=0 --refjar=$reference --destdir=/tmp/$job_id  --args=-2_-u_-n_-q --haploid_args=-r_0.0001 --diploid_args=-r_0.00005_-e_0.0001 --basequal=! --partition=1000000 --haploids=all --replace-uscores
      params: -D stream.num.map.output.key.fields=3
              -D mapred.text.key.partitioner.options=-k1,2
              -Dmapred.reduce.slowstart.completed.maps=1.0
              -Dmapred.task.timeout=1200000
              -Dio.sort.mb=700
              -input $temp/align
              -output $temp/snp
              -numReduceTasks 280
              -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner
              -file Soapsnp.pl
              -file Get.pm
              -file Counters.pm
              -file Util.pm
              -file Tools.pm
              -file AWS.pm



    - name: Postprocess
      mapper: /bin/cat
      reducer: CBFinish.pl  --cmapjar=$reference --destdir=/tmp/$job_id --output=$output
      params: -D stream.num.map.output.key.fields=2
              -D mapred.text.key.partitioner.options=-k1,1
              -input $temp/snp
              -output $tempignoreme2
              -numReduceTasks 30
              -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner
              -file CBFinish.pl
              -file Get.pm
              -file Counters.pm
              -file Util.pm
              -file Tools.pm
              -file AWS.pm


  inputs:
    - id: forwardReads
      description: Forward reads
      type: hdfs-folder

    - id: reverseReads
      description: Reverse reads
      type: hdfs-folder



    - id: reference
      description: Reference in JAR format
      type: hdfs-file

    - id: bowtie_arguments
      description: Reporting mode agruments for  Bowtie
      type: text
      value: -M 1 -X 600 --chunkmbs 200 
      required: false

    - id: quality
      description: Quality encoding
      type: list
      values: 
        phred33: phred33 encoding
        phred64: phred64
        solexa64: solexa64
      value: phred33

    - id: header_separator
      description: A symbol distinguishing forward and reverse reads in a FASTQ file
      type: list
      values:
       '/': Illumina < 1.8, symbol '/'
       'space': Illumina >=1.8, symbol 'space'
       'none': SRA->FASTQ, identical headers for a pair
      value: '/'
      required: true

  outputs:
    - id: output
      description: Output Folder
      type: hdfs-folder
      mergeOutput: false
      download: true
      zip: false

    - id: temp 
      description: Temp
      type: hdfs-folder
      download: false
      temp: true
